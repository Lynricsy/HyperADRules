name: Process Domain Lists

on:
  push:
    branches:
      - main
  workflow_dispatch:
  schedule:
    - cron: '0 * * * *'  # 每小时触发一次

jobs:
  process_domains:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Set Up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y curl

    - name: Download and Process Domain Lists
      run: |
        #!/bin/bash

        # Define the URLs
        urls=(
          "https://raw.githubusercontent.com/Cats-Team/AdRules/script/script/allowlist.txt"
          "https://raw.githubusercontent.com/privacy-protection-tools/dead-horse/master/anti-ad-white-list.txt"
          # Add other URLs here if needed
        )

        # Download and process each URL
        for url in "${urls[@]}"; do
          filename=$(basename "$url")
          
          # Process and save the file with @@||...^ format
          curl -s "$url" | awk '!/^#|^!/{ print "@@||" $0 "^" }' > "processed_${filename}_with_prefix.txt"

          # Process and save the file with just the domain names
          curl -s "$url" | awk '!/^#|^!/{ print $0 }' > "processed_${filename}_pure_domain.txt"
        done

        # Merge processed files into allow.txt (with @@||...^)
        cat processed_*_with_prefix.txt | sort -u > allow.txt

        # Merge processed files into pure_domains.txt (just domain names)
        cat processed_*_pure_domain.txt | sort -u > pure_domains.txt

        # Create the target directory if it does not exist
        mkdir -p data/rules

        # Move the generated files to the processed folder
        mv allow.txt data/rules/
        mv pure_domains.txt data/rules/

    - name: Commit and Push Changes
      uses: EndBug/add-and-commit@v9
      with:
        add: |
          data/rules/allow.txt
          data/rules/pure_domains.txt
        message: 'Update domain rules with new data'
